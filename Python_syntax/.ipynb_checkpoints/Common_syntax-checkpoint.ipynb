{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "data_train = pd.read_csv(\"/Users/yenlinh/Documents/GitHub/Data_Science_Project/Titanic/raw_data/train.csv\")\n",
    "# read excel\n",
    "df = pd.read_excel (r'Path where the Excel file is stored\\File name.xlsx', sheet_name='Type here the name of your Excel sheet')\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "summary.to_csv('period_lacking_exchangerate.csv', header=True,index=None)\n",
    "# write excel\n",
    "file_name = 'QI-9178_signup&KYC_' + str(yesterday) + \".xlsx\"\n",
    "writer = pd.ExcelWriter(file_name, engine='xlsxwriter')\n",
    "sheet_2.to_excel(writer, sheet_name='Summary_total', index=None)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1_value.describe())\n",
    "print(data1_value.info())\n",
    "print(raw_data.shape)\n",
    "print(raw_data.columns)\n",
    "# Count NA values\n",
    "print('NUll: ',data1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df by filter columns\n",
    "data= raw_data.loc[:,('user_id','last_execution_date','nb_trading_days','delta_balance','total_deposit')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with median, mode\n",
    "dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "column_drop=['PassengerId','Cabin','Ticket'] \n",
    "data1.drop(column_drop, axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare condition and assign value in 1 column\n",
    "dataset['IsAlone']=1\n",
    "dataset['IsAlone'].loc[dataset['FamilySize']>1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "dataset['Title']= dataset['Name'].str.split(\", \", expand=True)[1].str.split(\". \",expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicate of each value in column\n",
    "data1['Title'].value_counts()\n",
    "\n",
    "# Check duplicate between columns\n",
    "shop_duplicate = raw_data[raw_data.duplicated(['shopid','item_name','item_description','price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function for values in 1 column\n",
    "dataset['Title'] = dataset['Title'].apply(lambda x: 'Misc' if title_names.loc[x]==True else x)\n",
    "kmeans_result['trade_volume'] = kmeans_result['trade_volume'].apply(lambda x: x/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles\n",
    "quantiles = user_1.quantile(q=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "quantiles = pd.DataFrame(data =quantiles, columns=['recency','fre_cmt','count_thread'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dictionary\n",
    "quantiles = quantiles.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map data cac cot thanh 1 cot\n",
    "user_1['RFM'] = user_1['Recency_Group'].map(str) + user_1['Frequency_Group'].map(str) + user_1['Thread_Group'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter nhieu dieu kien\n",
    "longtimereturn_sample = user_1[(user_1['Recency_Group']>=4) & (user_1['Frequency_Group']==1)]\n",
    "\n",
    "result_df= result_df.loc[:,['currency','captured_date','uf_get_usd_rate_for_currency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by\n",
    "count_group= user_1.groupby(['Recency_Group','Frequency_Group'])['user_id'].count()\n",
    "\n",
    "kmeans_group = kmeans_group.groupby('Cluster').agg({'user_id': 'nunique',\n",
    "                                                      'recency':'mean',\n",
    "                                                      'nb_trading_days':'mean',\n",
    "                                                      'open_balance':'mean',\n",
    "                                                     'sum_DW':'mean',\n",
    "                                                     'trade_volume':'mean'})\n",
    "\n",
    "data.groupby('month', as_index=False).agg({\"duration\": \"sum\"})\n",
    "\n",
    "data[data['item'] == 'call'].groupby('month').agg(\n",
    "    # Get max of the duration column for each group\n",
    "    max_duration=('duration', max),\n",
    "    # Get min of the duration column for each group\n",
    "    min_duration=('duration', min),\n",
    "    # Get sum of the duration column for each group\n",
    "    total_duration=('duration', sum),\n",
    "    # Apply a lambda to date column\n",
    "    num_days=(\"date\", lambda x: (max(x) - min(x)).days)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by and rename.\n",
    "# Group by create set \n",
    "data_use_agglist = data_use.groupby('riderId').agg(\n",
    "    nb_dvc = pd.NamedAgg(column='dvc_id', aggfunc= 'nunique'),\n",
    "    dvc_id_list = pd.NamedAgg(column='dvc_id', aggfunc= set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "count_group= pd.DataFrame(count_group).reset_index()\n",
    "# reset index\n",
    "result_df = result_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "user_kmeans = pd.DataFrame(data=user_kmeans, columns=['user_id','username','last_activity'])\n",
    "user_kmeans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "data = data.rename(columns={'uf_get_usd_rate_for_currency':'exchange_rate'})\n",
    "\n",
    "# Get columns of dataframe\n",
    "cols_plot = reshape_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby\n",
    "top_3_pre = top_3_pre.groupby('shopid')['itemid'].nunique()\n",
    "# Sort value \n",
    "top_3_pre.sort_values(by=[\"itemid\"], axis=0, ascending=False, inplace=True, na_position ='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot dataframe\n",
    "reshape_data_plt = reshape_data.pivot(index='year_month', columns= 'currency', values='exchange_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datetime to strptime\n",
    "check['last_execution_date'] = check['last_execution_date'].apply(lambda x : dt.datetime.strptime(x, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# Get year/month/day\n",
    "data['year']=data['captured_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").strftime(\"%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object into code\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "label = LabelEncoder()\n",
    "temp['Sex_code']=label.fit_transform(temp['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare']\n",
      "['Survived', ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare']]\n"
     ]
    }
   ],
   "source": [
    "# Expand List\n",
    "target = ['Survived']\n",
    "data1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare']\n",
    "data1_xy =  target + data1_x_calc\n",
    "target.append(data1_x_calc)\n",
    "print(data1_xy)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Y': 1, 'N': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dict with 2 list\n",
    "encode_dict = dict(zip(list(\"YYNNYN\"),[1,1,0,0,1,0]))\n",
    "encode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List keys in Dict\n",
    "d = {'A':[1,2,3],\n",
    "    'B':[4,5,6],\n",
    "     'C':[7,8,9]\n",
    "    }\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time execute\n",
    "t0 = datetime.datetime.now()\n",
    "t1 = datetime.datetime.now()\n",
    "print('Execution time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data frame\n",
    "result_row = pd.DataFrame(row, columns=cols)\n",
    "\n",
    "# Create Df from Dict\n",
    "summary = pd.DataFrame.from_dict(dict_nacur, orient='index', columns=['month_null_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter isin and not isin\n",
    "new_df.loc[raw_data.index.isin(shop_duplicate.index), 'is_duplicated'] = True   \n",
    "new_df.loc[~raw_data.index.isin(shop_duplicate.index), 'is_duplicated'] = False  \n",
    "\n",
    "df.countries.isin(countries)\n",
    "df[df.countries.isin(countries)]\n",
    "df[~df.countries.isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row bind dataframe\n",
    "result_df=result_df.append(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open text file and write\n",
    "exists = os.path.isfile(filename)\n",
    "if exists:\n",
    "  print('Exists: '+filename)\n",
    "else:\n",
    "  print('Create: '+filename)\n",
    "  with open(filename,'w') as outfile:\n",
    "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/map'\n",
    "    parameters = {}\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(url, params=parameters)\n",
    "    data = json.loads(response.text)\n",
    "    for d in data[\"data\"]:\n",
    "      cryptos_list = cryptos_list + ',' + d[\"symbol\"]\n",
    "    outfile.write(cryptos_list.strip(','))\n",
    "\n",
    "print('Get Cryptos from Coinmarket: Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA\n",
    "import scipy.stats as st\n",
    "st.f_oneway(sample1, sample2, ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation and Correlation computation\n",
    "import scipy.stats as st\n",
    "st.pearsonr(sample1, sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/exploratory-data-analysis-in-python-set-2/\n",
    "# Plot BARPPLOT\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax1 = plt.subplots() \n",
    "fig.set_size_inches(15,  9) \n",
    "  \n",
    "  \n",
    "ax1 = sns.barplot(x =\"State\", y =\"Population\",  \n",
    "                  data = data.sort_values('MurderRate'),  \n",
    "                                        palette =\"Set2\") \n",
    "  \n",
    "ax1.set(xlabel ='States', ylabel ='Population In Millions') \n",
    "ax1.set_title('Population in Millions by State', size = 20) \n",
    "  \n",
    "plt.xticks(rotation =-90) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Deviation\n",
    "Population_std = data.Population.std() \n",
    "print (\"Population std : \", Population_std) \n",
    "\n",
    "#Variance\n",
    "Population_var = data.Population.var() \n",
    "print (\"Population var : \", Population_var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NA: axis la truc, cot\n",
    "# it is along rows i.e. axis = 0 \n",
    "dframe.dropna(inplace = True) \n",
    "print(dframe) \n",
    "  \n",
    "# if axis is equal to 1 \n",
    "dframe.dropna(axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Program to create\n",
    "# a data type object\n",
    "import numpy as np\n",
    " \n",
    "# First Array\n",
    "arr1 = np.array([[4, 7], [2, 6]], \n",
    "                 dtype = np.float64)\n",
    "                  \n",
    "# Second Array\n",
    "arr2 = np.array([[3, 6], [2, 8]], \n",
    "                 dtype = np.float64) \n",
    " \n",
    "# Addition of two Arrays\n",
    "Sum = np.add(arr1, arr2)\n",
    "print(\"Addition of Two Arrays: \")\n",
    "print(Sum)\n",
    " \n",
    "# Addition of all Array elements\n",
    "# using predefined sum method\n",
    "Sum1 = np.sum(arr1)\n",
    "print(\"\\nAddition of Array elements: \")\n",
    "print(Sum1)\n",
    " \n",
    "# Square root of Array\n",
    "Sqrt = np.sqrt(arr1)\n",
    "print(\"\\nSquare root of Array1 elements: \")\n",
    "print(Sqrt)\n",
    " \n",
    "# Transpose of Array\n",
    "# using In-built function 'T'\n",
    "Trans_arr = arr1.T\n",
    "print(\"\\nTranspose of Array: \")\n",
    "print(Trans_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition in sql\n",
    "SELECT currency_id, usdrate,capturedate\n",
    "                    FROM \n",
    "                    (\n",
    "                    SELECT currency_id, usdrate,capturedate,\n",
    "                           row_number() OVER (PARTITION BY currency_id ORDER BY capturedate DESC) as nb_row\n",
    "                    FROM dm_fact.exc01_exchange_consolidation\n",
    "                    WHERE currency_id in (20,22,24)\n",
    "                    and capturedate < v_from_time\n",
    "                    ) as r \n",
    "                    WHERE nb_row =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3 -3]\n",
      "\n",
      " Elements are : \n",
      " [2 4 7]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(np.array([1, 3, -3]))\n",
    "arr = x[np.array([1, 3, -3])] \n",
    "print(\"\\n Elements are : \\n\",arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "Modified array is:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Reshape array\n",
    "import numpy as geek\n",
    "a = geek.arange(12)\n",
    "print(a)\n",
    "a = a.reshape(3,4)\n",
    "print(a)\n",
    "b = a.T \n",
    "print('Modified array is:')\n",
    "for x in geek.nditer(b): \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframe\n",
    "merge_gr2_rider = pd.merge(merge_gr2_rider, rider_2, left_on =\"dvc_id\", right_on=\"dvc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby column to agg list\n",
    "df1 = df.groupby('a')['b'].apply(list).reset_index(name='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to dict\n",
    "df.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join string in dataframe:\n",
    "results_dvc_group = results.groupby(['deviceId_list','number_deviceId']).agg(\n",
    "    group_set = pd.NamedAgg(column='group_code', aggfunc= \",\".join))\n",
    "# Split and unique in line of 1 column dataframe:\n",
    "results_dvc_group['group_rider'] = results_dvc_group['group_rider'].str.split(',', expand=False).agg([set]).agg([list])\n",
    "# Replace string:\n",
    "results_dvc_group['deviceId_list'] = results_dvc_group['deviceId_list'].str.replace(\" \",\"\").str.replace(\"'\",\"\").str.replace(\"{\",\"\").str.replace(\"}\",\"\").str.split(',', expand=False).agg([set]).agg([list])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 2 dataframe:\n",
    "df_train = pd.read_csv('train.csv').drop(columns=['trip_duration', 'dropoff_datetime'])\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df = pd.concat([df_train, df_test], sort=False, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
