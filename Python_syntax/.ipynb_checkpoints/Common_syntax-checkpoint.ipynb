{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "data_train = pd.read_csv(\"/Users/yenlinh/Documents/GitHub/Data_Science_Project/Titanic/raw_data/train.csv\")\n",
    "# read excel\n",
    "df = pd.read_excel (r'Path where the Excel file is stored\\File name.xlsx', sheet_name='Type here the name of your Excel sheet')\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "summary.to_csv('period_lacking_exchangerate.csv', header=True,index=None)\n",
    "# write excel\n",
    "file_name = 'QI-9178_signup&KYC_' + str(yesterday) + \".xlsx\"\n",
    "writer = pd.ExcelWriter(file_name, engine='xlsxwriter')\n",
    "sheet_2.to_excel(writer, sheet_name='Summary_total', index=None)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1_value.describe())\n",
    "print(data1_value.info())\n",
    "print(raw_data.shape)\n",
    "print(raw_data.columns)\n",
    "# Count NA values\n",
    "print('NUll: ',data1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df by filter columns\n",
    "data= raw_data.loc[:,('user_id','last_execution_date','nb_trading_days','delta_balance','total_deposit')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with median, mode\n",
    "dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "column_drop=['PassengerId','Cabin','Ticket'] \n",
    "data1.drop(column_drop, axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare condition and assign value in 1 column\n",
    "dataset['IsAlone']=1\n",
    "dataset['IsAlone'].loc[dataset['FamilySize']>1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "dataset['Title']= dataset['Name'].str.split(\", \", expand=True)[1].str.split(\". \",expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicate of each value in column\n",
    "data1['Title'].value_counts()\n",
    "\n",
    "# Check duplicate between columns\n",
    "shop_duplicate = raw_data[raw_data.duplicated(['shopid','item_name','item_description','price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function for values in 1 column\n",
    "dataset['Title'] = dataset['Title'].apply(lambda x: 'Misc' if title_names.loc[x]==True else x)\n",
    "kmeans_result['trade_volume'] = kmeans_result['trade_volume'].apply(lambda x: x/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles\n",
    "quantiles = user_1.quantile(q=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "quantiles = pd.DataFrame(data =quantiles, columns=['recency','fre_cmt','count_thread'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dictionary\n",
    "quantiles = quantiles.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map data cac cot thanh 1 cot\n",
    "user_1['RFM'] = user_1['Recency_Group'].map(str) + user_1['Frequency_Group'].map(str) + user_1['Thread_Group'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter nhieu dieu kien\n",
    "longtimereturn_sample = user_1[(user_1['Recency_Group']>=4) & (user_1['Frequency_Group']==1)]\n",
    "\n",
    "result_df= result_df.loc[:,['currency','captured_date','uf_get_usd_rate_for_currency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by\n",
    "count_group= user_1.groupby(['Recency_Group','Frequency_Group'])['user_id'].count()\n",
    "\n",
    "kmeans_group = kmeans_group.groupby('Cluster').agg({'user_id': 'nunique',\n",
    "                                                      'recency':'mean',\n",
    "                                                      'nb_trading_days':'mean',\n",
    "                                                      'open_balance':'mean',\n",
    "                                                     'sum_DW':'mean',\n",
    "                                                     'trade_volume':'mean'})\n",
    "\n",
    "data.groupby('month', as_index=False).agg({\"duration\": \"sum\"})\n",
    "\n",
    "data[data['item'] == 'call'].groupby('month').agg(\n",
    "    # Get max of the duration column for each group\n",
    "    max_duration=('duration', max),\n",
    "    # Get min of the duration column for each group\n",
    "    min_duration=('duration', min),\n",
    "    # Get sum of the duration column for each group\n",
    "    total_duration=('duration', sum),\n",
    "    # Apply a lambda to date column\n",
    "    num_days=(\"date\", lambda x: (max(x) - min(x)).days)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "count_group= pd.DataFrame(count_group).reset_index()\n",
    "# reset index\n",
    "result_df = result_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "user_kmeans = pd.DataFrame(data=user_kmeans, columns=['user_id','username','last_activity'])\n",
    "user_kmeans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "data = data.rename(columns={'uf_get_usd_rate_for_currency':'exchange_rate'})\n",
    "\n",
    "# Get columns of dataframe\n",
    "cols_plot = reshape_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby\n",
    "top_3_pre = top_3_pre.groupby('shopid')['itemid'].nunique()\n",
    "# Sort value \n",
    "top_3_pre.sort_values(by=[\"itemid\"], axis=0, ascending=False, inplace=True, na_position ='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot dataframe\n",
    "reshape_data_plt = reshape_data.pivot(index='year_month', columns= 'currency', values='exchange_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datetime to strptime\n",
    "check['last_execution_date'] = check['last_execution_date'].apply(lambda x : dt.datetime.strptime(x, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# Get year/month/day\n",
    "data['year']=data['captured_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").strftime(\"%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object into code\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "label = LabelEncoder()\n",
    "temp['Sex_code']=label.fit_transform(temp['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare']\n",
      "['Survived', ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare']]\n"
     ]
    }
   ],
   "source": [
    "# Expand List\n",
    "target = ['Survived']\n",
    "data1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare']\n",
    "data1_xy =  target + data1_x_calc\n",
    "target.append(data1_x_calc)\n",
    "print(data1_xy)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Y': 1, 'N': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dict with 2 list\n",
    "encode_dict = dict(zip(list(\"YYNNYN\"),[1,1,0,0,1,0]))\n",
    "encode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List keys in Dict\n",
    "d = {'A':[1,2,3],\n",
    "    'B':[4,5,6],\n",
    "     'C':[7,8,9]\n",
    "    }\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time execute\n",
    "t0 = datetime.datetime.now()\n",
    "t1 = datetime.datetime.now()\n",
    "print('Execution time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data frame\n",
    "result_row = pd.DataFrame(row, columns=cols)\n",
    "\n",
    "# Create Df from Dict\n",
    "summary = pd.DataFrame.from_dict(dict_nacur, orient='index', columns=['month_null_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter isin and not isin\n",
    "new_df.loc[raw_data.index.isin(shop_duplicate.index), 'is_duplicated'] = True   \n",
    "new_df.loc[~raw_data.index.isin(shop_duplicate.index), 'is_duplicated'] = False  \n",
    "\n",
    "df.countries.isin(countries)\n",
    "df[df.countries.isin(countries)]\n",
    "df[~df.countries.isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row bind dataframe\n",
    "result_df=result_df.append(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open text file and write\n",
    "exists = os.path.isfile(filename)\n",
    "if exists:\n",
    "  print('Exists: '+filename)\n",
    "else:\n",
    "  print('Create: '+filename)\n",
    "  with open(filename,'w') as outfile:\n",
    "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/map'\n",
    "    parameters = {}\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(url, params=parameters)\n",
    "    data = json.loads(response.text)\n",
    "    for d in data[\"data\"]:\n",
    "      cryptos_list = cryptos_list + ',' + d[\"symbol\"]\n",
    "    outfile.write(cryptos_list.strip(','))\n",
    "\n",
    "print('Get Cryptos from Coinmarket: Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition in sql\n",
    "SELECT currency_id, usdrate,capturedate\n",
    "                    FROM \n",
    "                    (\n",
    "                    SELECT currency_id, usdrate,capturedate,\n",
    "                           row_number() OVER (PARTITION BY currency_id ORDER BY capturedate DESC) as nb_row\n",
    "                    FROM dm_fact.exc01_exchange_consolidation\n",
    "                    WHERE currency_id in (20,22,24)\n",
    "                    and capturedate < v_from_time\n",
    "                    ) as r \n",
    "                    WHERE nb_row =1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
